<?php

$speakers[] = array (
  'name' => 'Juozas Joe Kaziukenas',
  'city' => 'New York, NY',
  'country' => 'USA',
  'twitter' => '',
  'image' => 'http://www.gravatar.com/avatar/9b1dc79f9ca74e47f98ff5ad9b5c46f3?s=200&d=http://cl.ly/image/2z1J1U351d2K/no-pic.jpg',
  'bio' => '',
  'talks' => array (
    array (
      'title' => 'Growing spiders to crawl the web',
      'text' => 'In most cases, the best place to get some data is right there in some website. The data owner might not have an API and is not really interested in providing you with data in any other form. So you are stuck trying to figure out how to scrape that data and makes sense of it. This is where web scraping comes in - building small applications which understand the semantics of some websites and can figure out how to extract and categorize information, eventually with even some machine learning. This talk goes through the basics of web scraping and teaches you how you could build them and not get IP-banned by every site out there. ',
    ),
    array (
      'title' => 'Process any amounts of data. Any time',
      'text' => 'Processing one billion database rows doesn\'t need to kill your web server. Really, it doesn\'t. Applying lazy evaluation ideas you can make your scripts handle as much data as there exists, never using more memory than one unit\'s size (for example a database row). Using clever iterators, cursors and streams I\'ll show you how you can reduce memory usage drastically, thus making your scripts more reliable and your sysadmins happy.',
    ),
  ),
);